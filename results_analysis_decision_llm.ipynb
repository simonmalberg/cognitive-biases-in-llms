{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Correctly calculate biasedness (i.e., considering weights and using AggregationMetric) - see decision_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe shape: (540000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Folder containing the CSV files\n",
    "folder_path = \"decision_datasets\"\n",
    "\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List to store the column names of each dataframe\n",
    "columns_list = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):  # Only process CSV files\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path)  # Load the CSV into a dataframe\n",
    "        dataframes.append(df)  # Store the dataframe\n",
    "        columns_list.append(set(df.columns))  # Store the columns as a set for comparison\n",
    "\n",
    "# Find the common columns across all dataframes\n",
    "common_columns = set.intersection(*columns_list)\n",
    "\n",
    "# Filter each dataframe to only keep the common columns\n",
    "filtered_dataframes = [df[list(common_columns)] for df in dataframes]\n",
    "\n",
    "# Concatenate the filtered dataframes into one large dataframe\n",
    "df = pd.concat(filtered_dataframes, ignore_index=True)\n",
    "\n",
    "# Show the result\n",
    "print(\"Combined dataframe shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bias\"] = df[\"bias\"].apply(\n",
    "    lambda x: re.sub(r'([a-z])([A-Z])', r'\\1 \\2', x)\n",
    ").replace({\n",
    "    'Escalation Of Commitment': 'Escalation of Commitment', \n",
    "    'Illusion Of Control': 'Illusion of Control',\n",
    "    'Self Serving Bias': 'Self-Serving Bias',\n",
    "    'In Group Bias': 'In-Group Bias',\n",
    "    'Status Quo Bias': 'Status-Quo Bias'\n",
    "})\n",
    "\n",
    "df[\"model\"] = df[\"model\"].replace({\n",
    "    'meta-llama/Llama-3.2-90B-Vision-Instruct': 'Llama-3.2-90B',\n",
    "    'meta-llama/Meta-Llama-3.1-8B-Instruct': 'Llama-3.1-8B',\n",
    "    'meta-llama/Meta-Llama-3.1-70B-Instruct': 'Llama-3.1-70B',\n",
    "    'gpt-4o-mini-2024-07-18': 'GPT-4o-mini',\n",
    "    'gpt-3.5-turbo-0125': 'GPT-3.5-Turbo'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>GPT-3.5-Turbo</th>\n",
       "      <th>GPT-4o-mini</th>\n",
       "      <th>Llama-3.1-70B</th>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <th>Qwen/Qwen2.5-72B-Instruct</th>\n",
       "      <th>accounts/fireworks/models/phi-3-vision-128k-instruct</th>\n",
       "      <th>accounts/yi-01-ai/models/yi-large</th>\n",
       "      <th>google/gemma-2-27b-it</th>\n",
       "      <th>google/gemma-2-9b-it</th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>meta-llama/Llama-3.2-1B-Instruct</th>\n",
       "      <th>meta-llama/Llama-3.2-3B-Instruct</th>\n",
       "      <th>meta-llama/Meta-Llama-3.1-405B-Instruct</th>\n",
       "      <th>microsoft/WizardLM-2-7B</th>\n",
       "      <th>microsoft/WizardLM-2-8x22B</th>\n",
       "      <th>mistral-small-2409</th>\n",
       "      <th>models/gemini-1.5-flash</th>\n",
       "      <th>models/gemini-1.5-pro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anchoring</th>\n",
       "      <td>0.350827</td>\n",
       "      <td>0.402845</td>\n",
       "      <td>0.641535</td>\n",
       "      <td>0.459008</td>\n",
       "      <td>0.625407</td>\n",
       "      <td>0.431060</td>\n",
       "      <td>0.489181</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0.360206</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.482855</td>\n",
       "      <td>0.399653</td>\n",
       "      <td>-0.049464</td>\n",
       "      <td>0.372813</td>\n",
       "      <td>0.372611</td>\n",
       "      <td>0.291206</td>\n",
       "      <td>0.405750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthropomorphism</th>\n",
       "      <td>-0.086767</td>\n",
       "      <td>-0.123300</td>\n",
       "      <td>-0.140983</td>\n",
       "      <td>-0.027250</td>\n",
       "      <td>-0.007248</td>\n",
       "      <td>-0.268550</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>-0.061183</td>\n",
       "      <td>-0.093250</td>\n",
       "      <td>-0.030867</td>\n",
       "      <td>-0.018345</td>\n",
       "      <td>-0.066367</td>\n",
       "      <td>-0.135429</td>\n",
       "      <td>-0.006154</td>\n",
       "      <td>-0.077439</td>\n",
       "      <td>-0.005567</td>\n",
       "      <td>-0.076517</td>\n",
       "      <td>-0.046733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Availability Heuristic</th>\n",
       "      <td>0.160017</td>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.253560</td>\n",
       "      <td>0.106506</td>\n",
       "      <td>0.147028</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>0.131289</td>\n",
       "      <td>0.110937</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>0.132650</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.141534</td>\n",
       "      <td>0.108550</td>\n",
       "      <td>-0.098035</td>\n",
       "      <td>0.210219</td>\n",
       "      <td>0.102322</td>\n",
       "      <td>0.041048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bandwagon Effect</th>\n",
       "      <td>0.796617</td>\n",
       "      <td>0.318450</td>\n",
       "      <td>0.084733</td>\n",
       "      <td>0.117535</td>\n",
       "      <td>0.531200</td>\n",
       "      <td>0.558983</td>\n",
       "      <td>0.559083</td>\n",
       "      <td>0.371350</td>\n",
       "      <td>0.071183</td>\n",
       "      <td>0.659533</td>\n",
       "      <td>0.038183</td>\n",
       "      <td>0.604567</td>\n",
       "      <td>0.337183</td>\n",
       "      <td>0.099447</td>\n",
       "      <td>0.121438</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>0.711133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confirmation Bias</th>\n",
       "      <td>0.089613</td>\n",
       "      <td>0.043256</td>\n",
       "      <td>0.692750</td>\n",
       "      <td>0.020210</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688960</td>\n",
       "      <td>0.718067</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>-0.184519</td>\n",
       "      <td>0.026844</td>\n",
       "      <td>-0.062277</td>\n",
       "      <td>0.340307</td>\n",
       "      <td>0.061679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                   GPT-3.5-Turbo  GPT-4o-mini  Llama-3.1-70B  \\\n",
       "bias                                                                \n",
       "Anchoring                    0.350827     0.402845       0.641535   \n",
       "Anthropomorphism            -0.086767    -0.123300      -0.140983   \n",
       "Availability Heuristic       0.160017     0.160558       0.253560   \n",
       "Bandwagon Effect             0.796617     0.318450       0.084733   \n",
       "Confirmation Bias            0.089613     0.043256       0.692750   \n",
       "\n",
       "model                   Llama-3.1-8B  Qwen/Qwen2.5-72B-Instruct  \\\n",
       "bias                                                              \n",
       "Anchoring                   0.459008                   0.625407   \n",
       "Anthropomorphism           -0.027250                  -0.007248   \n",
       "Availability Heuristic      0.106506                   0.147028   \n",
       "Bandwagon Effect            0.117535                   0.531200   \n",
       "Confirmation Bias           0.020210                   0.297500   \n",
       "\n",
       "model                   accounts/fireworks/models/phi-3-vision-128k-instruct  \\\n",
       "bias                                                                           \n",
       "Anchoring                                                        0.431060      \n",
       "Anthropomorphism                                                -0.268550      \n",
       "Availability Heuristic                                           0.016126      \n",
       "Bandwagon Effect                                                 0.558983      \n",
       "Confirmation Bias                                                0.015773      \n",
       "\n",
       "model                   accounts/yi-01-ai/models/yi-large  \\\n",
       "bias                                                        \n",
       "Anchoring                                        0.489181   \n",
       "Anthropomorphism                                 0.012133   \n",
       "Availability Heuristic                           0.131289   \n",
       "Bandwagon Effect                                 0.559083   \n",
       "Confirmation Bias                                0.000000   \n",
       "\n",
       "model                   google/gemma-2-27b-it  google/gemma-2-9b-it  \\\n",
       "bias                                                                  \n",
       "Anchoring                            0.327632              0.360206   \n",
       "Anthropomorphism                    -0.061183             -0.093250   \n",
       "Availability Heuristic               0.110937              0.088508   \n",
       "Bandwagon Effect                     0.371350              0.071183   \n",
       "Confirmation Bias                    0.688960              0.718067   \n",
       "\n",
       "model                   gpt-4o-2024-08-06  meta-llama/Llama-3.2-1B-Instruct  \\\n",
       "bias                                                                          \n",
       "Anchoring                        0.604762                          0.147727   \n",
       "Anthropomorphism                -0.030867                         -0.018345   \n",
       "Availability Heuristic           0.132650                          0.066667   \n",
       "Bandwagon Effect                 0.659533                          0.038183   \n",
       "Confirmation Bias                0.004600                          0.044944   \n",
       "\n",
       "model                   meta-llama/Llama-3.2-3B-Instruct  \\\n",
       "bias                                                       \n",
       "Anchoring                                       0.482855   \n",
       "Anthropomorphism                               -0.066367   \n",
       "Availability Heuristic                          0.021098   \n",
       "Bandwagon Effect                                0.604567   \n",
       "Confirmation Bias                              -0.184519   \n",
       "\n",
       "model                   meta-llama/Meta-Llama-3.1-405B-Instruct  \\\n",
       "bias                                                              \n",
       "Anchoring                                              0.399653   \n",
       "Anthropomorphism                                      -0.135429   \n",
       "Availability Heuristic                                 0.141534   \n",
       "Bandwagon Effect                                       0.337183   \n",
       "Confirmation Bias                                      0.026844   \n",
       "\n",
       "model                   microsoft/WizardLM-2-7B  microsoft/WizardLM-2-8x22B  \\\n",
       "bias                                                                          \n",
       "Anchoring                             -0.049464                    0.372813   \n",
       "Anthropomorphism                      -0.006154                   -0.077439   \n",
       "Availability Heuristic                 0.108550                   -0.098035   \n",
       "Bandwagon Effect                       0.099447                    0.121438   \n",
       "Confirmation Bias                     -0.062277                    0.340307   \n",
       "\n",
       "model                   mistral-small-2409  models/gemini-1.5-flash  \\\n",
       "bias                                                                  \n",
       "Anchoring                         0.372611                 0.291206   \n",
       "Anthropomorphism                 -0.005567                -0.076517   \n",
       "Availability Heuristic            0.210219                 0.102322   \n",
       "Bandwagon Effect                  0.014350                 0.188017   \n",
       "Confirmation Bias                 0.061679                 0.000000   \n",
       "\n",
       "model                   models/gemini-1.5-pro  \n",
       "bias                                           \n",
       "Anchoring                            0.405750  \n",
       "Anthropomorphism                    -0.046733  \n",
       "Availability Heuristic               0.041048  \n",
       "Bandwagon Effect                     0.711133  \n",
       "Confirmation Bias                    0.088300  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build aggregated results table\n",
    "df_results = df.pivot_table(values='individual_score', index='bias', columns='model', aggfunc='mean')\n",
    "models = list(df_results.columns.values)\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Sub-Group</th>\n",
       "      <th>Publications (Overall)</th>\n",
       "      <th>Publications (Management)</th>\n",
       "      <th>Decision LLM during Test Development</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prejudice</th>\n",
       "      <td>What Should We Remember?</td>\n",
       "      <td>We discard specifics to form generalities</td>\n",
       "      <td>462000</td>\n",
       "      <td>16800</td>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>Exclude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conservatism</th>\n",
       "      <td>Too Much Information</td>\n",
       "      <td>We notice when something has changed.</td>\n",
       "      <td>232000</td>\n",
       "      <td>10600</td>\n",
       "      <td>GPT-3.5-Turbo</td>\n",
       "      <td>Test cases generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anchoring</th>\n",
       "      <td>Too Much Information</td>\n",
       "      <td>We notice when something has changed.</td>\n",
       "      <td>148000</td>\n",
       "      <td>9750</td>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>Test cases generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stereotyping</th>\n",
       "      <td>Not Enough Meaning</td>\n",
       "      <td>We fill in characteristics from stereotypes, g...</td>\n",
       "      <td>153000</td>\n",
       "      <td>5800</td>\n",
       "      <td>GPT-3.5-Turbo</td>\n",
       "      <td>Test cases generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Desirability Bias</th>\n",
       "      <td>Need To Act Fast</td>\n",
       "      <td>To act, we must be confident we can make an im...</td>\n",
       "      <td>49600</td>\n",
       "      <td>2600</td>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>Test cases generated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Group  \\\n",
       "bias                                                 \n",
       "Prejudice                 What Should We Remember?   \n",
       "Conservatism                  Too Much Information   \n",
       "Anchoring                     Too Much Information   \n",
       "Stereotyping                    Not Enough Meaning   \n",
       "Social Desirability Bias          Need To Act Fast   \n",
       "\n",
       "                                                                  Sub-Group  \\\n",
       "bias                                                                          \n",
       "Prejudice                         We discard specifics to form generalities   \n",
       "Conservatism                          We notice when something has changed.   \n",
       "Anchoring                             We notice when something has changed.   \n",
       "Stereotyping              We fill in characteristics from stereotypes, g...   \n",
       "Social Desirability Bias  To act, we must be confident we can make an im...   \n",
       "\n",
       "                          Publications (Overall)  Publications (Management)  \\\n",
       "bias                                                                          \n",
       "Prejudice                                 462000                      16800   \n",
       "Conservatism                              232000                      10600   \n",
       "Anchoring                                 148000                       9750   \n",
       "Stereotyping                              153000                       5800   \n",
       "Social Desirability Bias                   49600                       2600   \n",
       "\n",
       "                         Decision LLM during Test Development  \\\n",
       "bias                                                            \n",
       "Prejudice                                       Llama-3.1-70B   \n",
       "Conservatism                                    GPT-3.5-Turbo   \n",
       "Anchoring                                       Llama-3.1-70B   \n",
       "Stereotyping                                    GPT-3.5-Turbo   \n",
       "Social Desirability Bias                        Llama-3.1-70B   \n",
       "\n",
       "                                        Status  \n",
       "bias                                            \n",
       "Prejudice                              Exclude  \n",
       "Conservatism              Test cases generated  \n",
       "Anchoring                 Test cases generated  \n",
       "Stereotyping              Test cases generated  \n",
       "Social Desirability Bias  Test cases generated  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the meta data csv with the assignment of decision LLMs\n",
    "df_metadata = pd.read_csv(\"biases_metadata.csv\", encoding = \"UTF-8\",sep =\";\")\n",
    "df_metadata[\"Bias\"] = df_metadata[\"Bias\"].str.title().replace({\n",
    "    'Escalation Of Commitment': 'Escalation of Commitment', \n",
    "    'Illusion Of Control': 'Illusion of Control',\n",
    "    'Self Serving Bias': 'Self-Serving Bias',\n",
    "    'In Group Bias': 'In-Group Bias',\n",
    "    'Status Quo Bias': 'Status-Quo Bias'\n",
    "    })\n",
    "df_metadata = df_metadata.rename({\"Bias\":\"bias\"}, axis = 1).set_index(\"bias\")\n",
    "\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dataframes to add decision LLM assignment column\n",
    "df_results = df_results.join(df_metadata[[\"Decision LLM during Test Development\"]], on='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision LLM during Test Development\n",
       "GPT-3.5-Turbo    0.164552\n",
       "Llama-3.1-70B    0.139279\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(\"Decision LLM during Test Development\").mean().transpose().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT-3.5-Turbo</th>\n",
       "      <th>GPT-4o-mini</th>\n",
       "      <th>Llama-3.1-70B</th>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <th>Qwen/Qwen2.5-72B-Instruct</th>\n",
       "      <th>accounts/fireworks/models/phi-3-vision-128k-instruct</th>\n",
       "      <th>accounts/yi-01-ai/models/yi-large</th>\n",
       "      <th>google/gemma-2-27b-it</th>\n",
       "      <th>google/gemma-2-9b-it</th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>meta-llama/Llama-3.2-1B-Instruct</th>\n",
       "      <th>meta-llama/Llama-3.2-3B-Instruct</th>\n",
       "      <th>meta-llama/Meta-Llama-3.1-405B-Instruct</th>\n",
       "      <th>microsoft/WizardLM-2-7B</th>\n",
       "      <th>microsoft/WizardLM-2-8x22B</th>\n",
       "      <th>mistral-small-2409</th>\n",
       "      <th>models/gemini-1.5-flash</th>\n",
       "      <th>models/gemini-1.5-pro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision LLM during Test Development</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT-3.5-Turbo</th>\n",
       "      <td>0.190136</td>\n",
       "      <td>0.174441</td>\n",
       "      <td>0.200852</td>\n",
       "      <td>0.174674</td>\n",
       "      <td>0.207726</td>\n",
       "      <td>0.249430</td>\n",
       "      <td>0.172129</td>\n",
       "      <td>0.206829</td>\n",
       "      <td>0.190679</td>\n",
       "      <td>0.224905</td>\n",
       "      <td>-0.004183</td>\n",
       "      <td>0.131006</td>\n",
       "      <td>0.167388</td>\n",
       "      <td>0.092053</td>\n",
       "      <td>0.189029</td>\n",
       "      <td>0.112540</td>\n",
       "      <td>0.139124</td>\n",
       "      <td>0.143185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-70B</th>\n",
       "      <td>0.115436</td>\n",
       "      <td>0.103910</td>\n",
       "      <td>0.209426</td>\n",
       "      <td>0.155445</td>\n",
       "      <td>0.115240</td>\n",
       "      <td>0.212252</td>\n",
       "      <td>0.146202</td>\n",
       "      <td>0.171538</td>\n",
       "      <td>0.061782</td>\n",
       "      <td>0.202895</td>\n",
       "      <td>0.067223</td>\n",
       "      <td>0.144460</td>\n",
       "      <td>0.163414</td>\n",
       "      <td>0.071337</td>\n",
       "      <td>0.116112</td>\n",
       "      <td>0.215635</td>\n",
       "      <td>0.128004</td>\n",
       "      <td>0.106715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      GPT-3.5-Turbo  GPT-4o-mini  \\\n",
       "Decision LLM during Test Development                               \n",
       "GPT-3.5-Turbo                              0.190136     0.174441   \n",
       "Llama-3.1-70B                              0.115436     0.103910   \n",
       "\n",
       "                                      Llama-3.1-70B  Llama-3.1-8B  \\\n",
       "Decision LLM during Test Development                                \n",
       "GPT-3.5-Turbo                              0.200852      0.174674   \n",
       "Llama-3.1-70B                              0.209426      0.155445   \n",
       "\n",
       "                                      Qwen/Qwen2.5-72B-Instruct  \\\n",
       "Decision LLM during Test Development                              \n",
       "GPT-3.5-Turbo                                          0.207726   \n",
       "Llama-3.1-70B                                          0.115240   \n",
       "\n",
       "                                      accounts/fireworks/models/phi-3-vision-128k-instruct  \\\n",
       "Decision LLM during Test Development                                                         \n",
       "GPT-3.5-Turbo                                                                  0.249430      \n",
       "Llama-3.1-70B                                                                  0.212252      \n",
       "\n",
       "                                      accounts/yi-01-ai/models/yi-large  \\\n",
       "Decision LLM during Test Development                                      \n",
       "GPT-3.5-Turbo                                                  0.172129   \n",
       "Llama-3.1-70B                                                  0.146202   \n",
       "\n",
       "                                      google/gemma-2-27b-it  \\\n",
       "Decision LLM during Test Development                          \n",
       "GPT-3.5-Turbo                                      0.206829   \n",
       "Llama-3.1-70B                                      0.171538   \n",
       "\n",
       "                                      google/gemma-2-9b-it  gpt-4o-2024-08-06  \\\n",
       "Decision LLM during Test Development                                            \n",
       "GPT-3.5-Turbo                                     0.190679           0.224905   \n",
       "Llama-3.1-70B                                     0.061782           0.202895   \n",
       "\n",
       "                                      meta-llama/Llama-3.2-1B-Instruct  \\\n",
       "Decision LLM during Test Development                                     \n",
       "GPT-3.5-Turbo                                                -0.004183   \n",
       "Llama-3.1-70B                                                 0.067223   \n",
       "\n",
       "                                      meta-llama/Llama-3.2-3B-Instruct  \\\n",
       "Decision LLM during Test Development                                     \n",
       "GPT-3.5-Turbo                                                 0.131006   \n",
       "Llama-3.1-70B                                                 0.144460   \n",
       "\n",
       "                                      meta-llama/Meta-Llama-3.1-405B-Instruct  \\\n",
       "Decision LLM during Test Development                                            \n",
       "GPT-3.5-Turbo                                                        0.167388   \n",
       "Llama-3.1-70B                                                        0.163414   \n",
       "\n",
       "                                      microsoft/WizardLM-2-7B  \\\n",
       "Decision LLM during Test Development                            \n",
       "GPT-3.5-Turbo                                        0.092053   \n",
       "Llama-3.1-70B                                        0.071337   \n",
       "\n",
       "                                      microsoft/WizardLM-2-8x22B  \\\n",
       "Decision LLM during Test Development                               \n",
       "GPT-3.5-Turbo                                           0.189029   \n",
       "Llama-3.1-70B                                           0.116112   \n",
       "\n",
       "                                      mistral-small-2409  \\\n",
       "Decision LLM during Test Development                       \n",
       "GPT-3.5-Turbo                                   0.112540   \n",
       "Llama-3.1-70B                                   0.215635   \n",
       "\n",
       "                                      models/gemini-1.5-flash  \\\n",
       "Decision LLM during Test Development                            \n",
       "GPT-3.5-Turbo                                        0.139124   \n",
       "Llama-3.1-70B                                        0.128004   \n",
       "\n",
       "                                      models/gemini-1.5-pro  \n",
       "Decision LLM during Test Development                         \n",
       "GPT-3.5-Turbo                                      0.143185  \n",
       "Llama-3.1-70B                                      0.106715  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get average bias score for each decision LLM\n",
    "df_results.groupby(\"Decision LLM during Test Development\").mean()\n",
    "\n",
    "# for most LLMs bias is higher for the group of biases tested with GPT-3.5-Turbo\n",
    "# this is not the case for the Llama models except Llama-3.1-8B\n",
    "# the other exception is also mistral-small-2409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every model get mean scores and rank overall and for each decision LLM\n",
    "\n",
    "ranks = []\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    ranks.append({\"Model\":model, \n",
    "     \"Overall Mean\":df_results[model].mean().round(2),\n",
    "     \"Overall Rank\": df_results.drop(\"Decision LLM during Test Development\", axis = 1).mean().sort_values(ascending=True).index.get_loc(model),\n",
    "     \"Mean with Decision LLM GPT-3.5-Turbo\": df_results.loc[df_results[\"Decision LLM during Test Development\"] == \"GPT-3.5-Turbo\",model].mean().round(2),\n",
    "    \"Rank with Decision LLM GPT-3.5-Turbo\": df_results.loc[df_results[\"Decision LLM during Test Development\"] == \"GPT-3.5-Turbo\"].drop(\"Decision LLM during Test Development\", axis = 1).mean().sort_values(ascending=True).index.get_loc(model),\n",
    "     \"Mean with Decision LLM Llama-3.1-70B\": df_results.loc[df_results[\"Decision LLM during Test Development\"] == \"Llama-3.1-70B\",model].mean().round(2),\n",
    "    \"Rank with Decision LLM Llama-3.1-70B\": df_results.loc[df_results[\"Decision LLM during Test Development\"] == \"Llama-3.1-70B\"].drop(\"Decision LLM during Test Development\", axis = 1).mean().sort_values(ascending=True).index.get_loc(model)})\n",
    "\n",
    "# higher rank means more bias \n",
    "df_ranks = pd.DataFrame.from_dict(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Overall Mean</th>\n",
       "      <th>Overall Rank</th>\n",
       "      <th>Mean with Decision LLM GPT-3.5-Turbo</th>\n",
       "      <th>Rank with Decision LLM GPT-3.5-Turbo</th>\n",
       "      <th>Mean with Decision LLM Llama-3.1-70B</th>\n",
       "      <th>Rank with Decision LLM Llama-3.1-70B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5-Turbo</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>0.19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4o-mini</td>\n",
       "      <td>0.14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>0.21</td>\n",
       "      <td>15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.17</td>\n",
       "      <td>12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accounts/fireworks/models/phi-3-vision-128k-in...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accounts/yi-01-ai/models/yi-large</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9</td>\n",
       "      <td>0.17</td>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>0.19</td>\n",
       "      <td>14</td>\n",
       "      <td>0.21</td>\n",
       "      <td>14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.19</td>\n",
       "      <td>12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>0.21</td>\n",
       "      <td>16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-405B-Instruct</td>\n",
       "      <td>0.17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>microsoft/WizardLM-2-7B</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>microsoft/WizardLM-2-8x22B</td>\n",
       "      <td>0.15</td>\n",
       "      <td>7</td>\n",
       "      <td>0.19</td>\n",
       "      <td>10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mistral-small-2409</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>models/gemini-1.5-flash</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>models/gemini-1.5-pro</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  Overall Mean  \\\n",
       "0                                       GPT-3.5-Turbo          0.15   \n",
       "1                                         GPT-4o-mini          0.14   \n",
       "2                                       Llama-3.1-70B          0.21   \n",
       "3                                        Llama-3.1-8B          0.17   \n",
       "4                           Qwen/Qwen2.5-72B-Instruct          0.16   \n",
       "5   accounts/fireworks/models/phi-3-vision-128k-in...          0.23   \n",
       "6                   accounts/yi-01-ai/models/yi-large          0.16   \n",
       "7                               google/gemma-2-27b-it          0.19   \n",
       "8                                google/gemma-2-9b-it          0.13   \n",
       "9                                   gpt-4o-2024-08-06          0.21   \n",
       "10                   meta-llama/Llama-3.2-1B-Instruct          0.03   \n",
       "11                   meta-llama/Llama-3.2-3B-Instruct          0.14   \n",
       "12            meta-llama/Meta-Llama-3.1-405B-Instruct          0.17   \n",
       "13                            microsoft/WizardLM-2-7B          0.08   \n",
       "14                         microsoft/WizardLM-2-8x22B          0.15   \n",
       "15                                 mistral-small-2409          0.16   \n",
       "16                            models/gemini-1.5-flash          0.13   \n",
       "17                              models/gemini-1.5-pro          0.12   \n",
       "\n",
       "    Overall Rank  Mean with Decision LLM GPT-3.5-Turbo  \\\n",
       "0              8                                  0.19   \n",
       "1              6                                  0.17   \n",
       "2             15                                  0.20   \n",
       "3             12                                  0.17   \n",
       "4             10                                  0.21   \n",
       "5             17                                  0.25   \n",
       "6              9                                  0.17   \n",
       "7             14                                  0.21   \n",
       "8              3                                  0.19   \n",
       "9             16                                  0.22   \n",
       "10             0                                 -0.00   \n",
       "11             5                                  0.13   \n",
       "12            13                                  0.17   \n",
       "13             1                                  0.09   \n",
       "14             7                                  0.19   \n",
       "15            11                                  0.11   \n",
       "16             4                                  0.14   \n",
       "17             2                                  0.14   \n",
       "\n",
       "    Rank with Decision LLM GPT-3.5-Turbo  \\\n",
       "0                                     11   \n",
       "1                                      8   \n",
       "2                                     13   \n",
       "3                                      9   \n",
       "4                                     15   \n",
       "5                                     17   \n",
       "6                                      7   \n",
       "7                                     14   \n",
       "8                                     12   \n",
       "9                                     16   \n",
       "10                                     0   \n",
       "11                                     3   \n",
       "12                                     6   \n",
       "13                                     1   \n",
       "14                                    10   \n",
       "15                                     2   \n",
       "16                                     4   \n",
       "17                                     5   \n",
       "\n",
       "    Mean with Decision LLM Llama-3.1-70B  Rank with Decision LLM Llama-3.1-70B  \n",
       "0                                   0.12                                     6  \n",
       "1                                   0.10                                     3  \n",
       "2                                   0.21                                    15  \n",
       "3                                   0.16                                    11  \n",
       "4                                   0.12                                     5  \n",
       "5                                   0.21                                    16  \n",
       "6                                   0.15                                    10  \n",
       "7                                   0.17                                    13  \n",
       "8                                   0.06                                     0  \n",
       "9                                   0.20                                    14  \n",
       "10                                  0.07                                     1  \n",
       "11                                  0.14                                     9  \n",
       "12                                  0.16                                    12  \n",
       "13                                  0.07                                     2  \n",
       "14                                  0.12                                     7  \n",
       "15                                  0.22                                    17  \n",
       "16                                  0.13                                     8  \n",
       "17                                  0.11                                     4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Overall Mean</th>\n",
       "      <th>Overall Rank</th>\n",
       "      <th>Mean with Decision LLM GPT-3.5-Turbo</th>\n",
       "      <th>Rank with Decision LLM GPT-3.5-Turbo</th>\n",
       "      <th>Mean with Decision LLM Llama-3.1-70B</th>\n",
       "      <th>Rank with Decision LLM Llama-3.1-70B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.1-70B</td>\n",
       "      <td>0.21</td>\n",
       "      <td>15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.17</td>\n",
       "      <td>12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-405B-Instruct</td>\n",
       "      <td>0.17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Overall Mean  Overall Rank  \\\n",
       "2                             Llama-3.1-70B          0.21            15   \n",
       "3                              Llama-3.1-8B          0.17            12   \n",
       "10         meta-llama/Llama-3.2-1B-Instruct          0.03             0   \n",
       "11         meta-llama/Llama-3.2-3B-Instruct          0.14             5   \n",
       "12  meta-llama/Meta-Llama-3.1-405B-Instruct          0.17            13   \n",
       "\n",
       "    Mean with Decision LLM GPT-3.5-Turbo  \\\n",
       "2                                   0.20   \n",
       "3                                   0.17   \n",
       "10                                 -0.00   \n",
       "11                                  0.13   \n",
       "12                                  0.17   \n",
       "\n",
       "    Rank with Decision LLM GPT-3.5-Turbo  \\\n",
       "2                                     13   \n",
       "3                                      9   \n",
       "10                                     0   \n",
       "11                                     3   \n",
       "12                                     6   \n",
       "\n",
       "    Mean with Decision LLM Llama-3.1-70B  Rank with Decision LLM Llama-3.1-70B  \n",
       "2                                   0.21                                    15  \n",
       "3                                   0.16                                    11  \n",
       "10                                  0.07                                     1  \n",
       "11                                  0.14                                     9  \n",
       "12                                  0.16                                    12  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranks.loc[df_ranks[\"Model\"].str.contains(\"Llama\")]\n",
    "\n",
    "# higher rank means higher bias\n",
    "\n",
    "# GPT models exhibit higher ranks for GPT-3.5-Turbo\n",
    "# GPT models exhibit lower ranks for Llama-3.1-70B\n",
    "# Llama models exhibit lower ranks for GPT-3.5-Turbo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

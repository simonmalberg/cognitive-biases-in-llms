from base import LLM
from openai import OpenAI
import yaml
import os


class Llama(LLM):
    """
    An abstract class representing Llama models by Meta provided by the DeepInfra API.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        if "DEEPINFRA_API" not in os.environ:
            raise ValueError(
                "Cannot access DeepInfra API due to missing API key. Please store your API key in environment variable 'DEEPINFRA_API'."
            )
        # The client object for the DeepInfra API (supports OpenAI API)
        self._CLIENT = OpenAI(
            base_url="https://api.deepinfra.com/v1/openai",
            api_key=os.environ["DEEPINFRA_API"],
        )
        self.RESPONSE_FORMAT = None
        with open("./models/Meta/prompts.yml") as f:
            self._PROMPTS = yaml.safe_load(f)

    def prompt(self, prompt: str, temperature: float = 0.0, seed: int = 42) -> str:
        """
        Generates a response to the provided prompt.

        Args:
            prompt (str): The prompt to generate a response for.
            temperature (float): The temperature value of the LLM. For strictly decision models, we use a temperature of 0.0.
            seed (int): The seed for controlling the LLM's output. It is not used in Llama models.

        Returns:
            str: The response generated by the LLM.
        """
        # Call the chat completions API endpoint
        response = self._CLIENT.chat.completions.create(
            model=self.NAME,
            temperature=temperature,
            messages=[{"role": "user", "content": prompt}],
        )

        # Extract and return the answer
        return response.choices[0].message.content


class LlamaThreePointOneFourHundredFiveB(Llama):
    """
    A class representing a Llama-3.1-405B-Instruct LLM.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        self.NAME = "meta-llama/Meta-Llama-3.1-405B-Instruct"


class LlamaThreePointOneSeventyB(Llama):
    """
    A class representing a Llama-3.1-70B-Instruct LLM.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        self.NAME = "meta-llama/Meta-Llama-3.1-70B-Instruct"


class LlamaThreePointOneEightB(Llama):
    """
    A class representing a Llama-3.1-8B-Instruct LLM.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        self.NAME = "meta-llama/Meta-Llama-3.1-8B-Instruct"
        

class LlamaThreePointTwoNinetyB(Llama):
    """
    A class representing a Llama-3.2-90B-Vision-Instruct LLM.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        self.NAME = "meta-llama/Llama-3.2-90B-Vision-Instruct"

class LlamaThreePointTwoOneB(Llama):
    """
    A class representing a Llama-3.2-1B-Instruct LLM.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        self.NAME = "meta-llama/Llama-3.2-1B-Instruct"


class LlamaThreePointTwoThreeB(Llama):
    """
    A class representing a Llama-3.2-3B-Instruct LLM.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        self.NAME = "meta-llama/Llama-3.2-3B-Instruct"
        

class LlamaThreePointTwoElevenB(Llama):
    """
    A class representing a Llama-3.2-11B-Vision-Instruct LLM.

    Attributes:
        NAME (str): The name of the model.
    """

    def __init__(
        self, randomly_flip_options: bool = False, shuffle_answer_options: bool = False
    ):
        super().__init__(
            randomly_flip_options=randomly_flip_options,
            shuffle_answer_options=shuffle_answer_options,
        )
        self.NAME = "meta-llama/Llama-3.2-11B-Vision-Instruct"

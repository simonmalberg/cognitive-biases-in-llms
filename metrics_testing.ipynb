{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the confidence variation of matrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$ — number of samples in a batch (if not specified otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchoring Bias Metric\n",
    "\n",
    "$\\hat{a}_1$ — option selected in the control part\n",
    "\n",
    "$\\hat{a}_2$ — option selected in the treatment part \n",
    "\n",
    "$\\tilde{a}_1 = \\text{arg}\\max\\limits_{a}\\,\\left\\Vert a - \\hat{a}_1 \\right\\Vert_1$ — the farthest answer option from $\\hat{a}_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_answer = np.array([[10], [10], [16], [5], [200]])\n",
    "treatment_answer = np.array([[10], [20], [4], [4], [100]])\n",
    "anchor = np.array([[10], [10], [4], [3], [30]])\n",
    "answer_options = np.array(\n",
    "    [\n",
    "        [10, 20, 30, 40],\n",
    "        [10, 20, 30, 40],\n",
    "        [4, 8, 16, 20],\n",
    "        [2, 3, 4, 5],\n",
    "        [100, 200, 300, 400],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguably, anchor can have both an “appealing” (pushing answer closer) and “unappealing” effects → hence, simply account for deviations in answers. Thus: \n",
    "\n",
    "Individual anchor-agnostic metric:\n",
    "\n",
    "$$\\mathfrak{B}_i = \\frac{\\left\\Vert \\hat{a}_2 - \\hat{a}_1 \\right\\Vert_1}{\\left\\Vert \\tilde{a}_1 - \\hat{a}_1 \\right\\Vert_1} \\in \\left[0,1\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.33333333],\n",
       "       [1.        ],\n",
       "       [0.33333333],\n",
       "       [0.5       ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_agnostic = AnchoringBiasMetric(anchor_agnostic=True, overall=False)\n",
    "anchor_agnostic.compute(control_answer, treatment_answer, answer_options, anchor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if we assume that anchor has only an “appealing” effect, we can use the following:\n",
    "\n",
    "Individual anchor-specific metric:\n",
    "\n",
    "$$\\mathfrak{B}_i^\\prime = \\max\\left(0, \\frac{\\left\\Vert \\hat{a}_1 - a^* \\right\\Vert_1 - \\left\\Vert \\hat{a}_2 - a^*\\right\\Vert_1}{\\left\\Vert \\hat{a}_1 - a^* \\right\\Vert_1}\\right) \\in \\left[0,1\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition: the closer to the anchor we become after moving from control to treatment, the larger the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0. ],\n",
       "       [1. ],\n",
       "       [0.5],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_specific = AnchoringBiasMetric(anchor_agnostic=False, overall=False)\n",
    "anchor_specific.compute(control_answer, treatment_answer, answer_options, anchor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch metric:\n",
    "\n",
    "$$\\mathfrak{B} = \\frac{\\mathfrak{B}_1 + ... +  \\mathfrak{B}_N}{N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4333333329716666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchor-agnostic\n",
    "anchor_batch = AnchoringBiasMetric(anchor_agnostic=True, overall=True)\n",
    "anchor_batch.compute(control_answer, treatment_answer, answer_options, anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999999993133334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchor-specific\n",
    "anchor_batch = AnchoringBiasMetric(anchor_agnostic=False, overall=True)\n",
    "anchor_batch.compute(control_answer, treatment_answer, answer_options, anchor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halo Effect Metric\n",
    "\n",
    "$\\hat{a}_1$ — option selected in the control part\n",
    "\n",
    "$\\hat{a}_2$ — option selected in the treatment part \n",
    "\n",
    "$\\tilde{a}_1 = \\text{arg}\\max\\limits_{a}\\,\\left\\Vert a - \\hat{a}_1 \\right\\Vert_1$ — the farthest answer option from $\\hat{a}_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_answer = np.array([[10], [10], [16], [5], [200]])\n",
    "treatment_answer = np.array([[10], [20], [4], [4], [100]])\n",
    "answer_options = np.array(\n",
    "    [\n",
    "        [10, 20, 30, 40],\n",
    "        [10, 20, 30, 40],\n",
    "        [4, 8, 16, 20],\n",
    "        [2, 3, 4, 5],\n",
    "        [100, 200, 300, 400],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual metric:\n",
    "\n",
    "$$\\mathfrak{B}_i = \\frac{\\left\\Vert \\hat{a}_2 - \\hat{a}_1 \\right\\Vert_1}{\\left\\Vert \\tilde{a}_1 - \\hat{a}_1 \\right\\Vert_1} \\in \\left[0,1\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.33333333],\n",
       "       [1.        ],\n",
       "       [0.33333333],\n",
       "       [0.5       ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halo_individual = HaloEffectMetric(overall=False)\n",
    "halo_individual.compute(control_answer, treatment_answer, answer_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch metric:\n",
    "\n",
    "$$\\mathfrak{B} = \\frac{\\mathfrak{B}_1 + ... +  \\mathfrak{B}_N}{N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4333333329716666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halo_batch = HaloEffectMetric(overall=True)\n",
    "halo_batch.compute(control_answer, treatment_answer, answer_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Aversion Metric\n",
    "\n",
    "$a_i$ — answer in the given test\n",
    "\n",
    "$\\lambda_i$ — respective loss aversion hyperparameter of the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_unbiased = np.array([[0], [1], [1], [1], [1], [1]])\n",
    "answer_biased = np.array([[0], [0], [0], [0], [1], [1]])\n",
    "lambdas = np.array([[1.0000001], [1.05], [1.1], [10], [100], [2000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual metric:\n",
    "\n",
    "$$\\mathfrak{B}_i = \\begin{cases} 1, \\, a_i = 1  \\\\ 0, \\, a_i = 0 \\end{cases} = a_i\\,\\,\\, \\forall i = 1, ..., n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Biased:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "la_individual = LossAversionMetric(overall=False)\n",
    "print(f\"Unbiased:\\n{la_individual.compute(answer_unbiased, lambdas)}\")\n",
    "print(f\"Biased:\\n{la_individual.compute(answer_biased, lambdas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch metric:\n",
    "\n",
    "$$\\mathfrak{B} = 1 -\\frac{\\sum_{i=1}^{N} \\frac{\\mathfrak{B}_i}{\\lambda_i}}{\\sum_{i = 1}^{N} \\frac{1}{\\lambda_i}} \\in \\left[0, 1\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition: if the agent rejects all tests, bias is maximum. Otherwise, the smaller the accepted $\\lambda_i$, the less biased is the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Almost) Unbiased: 0.33647691844311445\n",
      "Biased: 0.9964669920030466\n"
     ]
    }
   ],
   "source": [
    "la_batch = LossAversionMetric(overall=True)\n",
    "print(\n",
    "    f\"(Almost) Unbiased: {la_batch.compute(answer_unbiased, lambdas)}\"\n",
    ")  # arguably needs to be even closer to zero\n",
    "print(f\"Biased: {la_batch.compute(answer_biased, lambdas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirmation Bias Metric\n",
    "\n",
    "$a_i \\in \\{0, 1\\}$ — chosen answer in the control version of the $i$-th test\n",
    "\n",
    "$a_i^+$ — number of pro-arguments selected in the treatment version of the $i$-th test\n",
    "\n",
    "$a_i^-$ — number of con-arguments selected in the treatment version of the $i$-th test\n",
    "\n",
    "$N_i$ — number of arguments in the treatment version of the $i$-th test\n",
    "\n",
    "$n$ — number of test cases in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = np.array([[0], [1], [0], [1], [0], [1], [0]])\n",
    "pro_answer = np.array([[2], [6], [1], [3], [4], [1], [1]])\n",
    "con_answer = np.array([[2], [6], [4], [0], [5], [2], [2]])\n",
    "n_args = np.array([[8], [12], [8], [6], [10], [10], [20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: the more options selected in the treatment part correspond to the initial control answer, the higher the bias. Besides, tests with higher number of answer options contribute more to the batch score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual metric:\n",
    "\n",
    "$$\\mathfrak{B}_i = \\max\\left(0, \\frac{a_i\\left(a_i^+ - a_i^-\\right) + \\left(1 - a_i\\right)\\left(a_i^+ - a_i^-\\right)}{a_i^+ + a_i^-}\\right)  \\in \\left[0, 1\\right]\\,\\,\\, \\forall i = 1, ..., n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.6       ],\n",
       "       [1.        ],\n",
       "       [0.11111111],\n",
       "       [0.        ],\n",
       "       [0.33333333]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_individual = ConfirmationBiasMetric(overall=False)\n",
    "conf_individual.compute(answer, pro_answer, con_answer, n_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch metric:\n",
    "\n",
    "$$\\mathfrak{B} = \\frac{\\mathfrak{B}_1N_1 + ... + \\mathfrak{B}_nN_n}{N_1 + ... + N_n} \\in \\left[0, 1\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.251051051051051"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_batch = ConfirmationBiasMetric(overall=True)\n",
    "conf_batch.compute(answer, pro_answer, con_answer, n_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
